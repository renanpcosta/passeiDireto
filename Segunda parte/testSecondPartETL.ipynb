{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testSecondPartETL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf-07RyFe43-",
        "outputId": "4d3805b7-91f6-45e4-d732-e57a869338d3"
      },
      "source": [
        "#@title Após executar esse parágrafo, irá aparecer um link para permitir o acesso ao seu drive. Basta copiar e colocar no local indicado e apertar 'ENTER'. { display-mode: \"both\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y3XbVgSN2Wx",
        "outputId": "851fdc5d-18e3-4408-b689-3d3e79204d62"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqRP-ileEWTL"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark import SparkContext, SparkConf\r\n",
        "from pyspark.sql.functions import col, lit, udf, split, desc, asc\r\n",
        "\r\n",
        "from unicodedata import normalize\r\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnWff2RGNat1"
      },
      "source": [
        "spark = SparkSession.builder.config(\"spark.executor.memory\", \"1gb\").getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtzzNVlB-tU1"
      },
      "source": [
        "#@title Fiz uma visão agrupada das colunas para entender melhor os dados do dataframe. Exclui as colunas que não considerei necessárias para atingir o objetivo proposto e também as que não fui capaz de entender o que significavam. Essas são as colunas que decidi utilizar. Vale ressaltar que assim como no primeiro teste, em um cenário real, eu entraria em contato com o time parceiro para validar os campos e obter insights. { display-mode: \"both\" }\n",
        "listColumnsToSelect = ['Page Category',\n",
        "                       'Page Category 1',\n",
        "                       'Page Category 2',\n",
        "                       'Page Category 3',\n",
        "                       'at',\n",
        "                       'browser',\n",
        "                       'carrier',\n",
        "                       'custom_4',\n",
        "                       'first-accessed-page',\n",
        "                       'marketing_campaign',\n",
        "                       'marketing_medium',\n",
        "                       'marketing_source',\n",
        "                       'model',\n",
        "                       'platform',\n",
        "                       'studentId_clientType',\n",
        "                       'uuid']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjlvRwOUe6zB"
      },
      "source": [
        "#@title Leitura dos arquivos json. Também separo da coluna studentId_clientType as informações de StudentId para usar como chave nos dataframes da Base A e o ClientType para análise. Vale destacar que não utilizei nenhum dataframe da Base A pois não achei nenhuma informação relevante para o objetivo proposto. O dataframe sessions.json era o mais promissor mas não tinha nenhum dado relevante. { display-mode: \"both\" }\n",
        "inputPath = '/content/drive/MyDrive/passeiDireto/BASE B/'\n",
        "dfPageViewEvents = spark.read.json(inputPath).select(listColumnsToSelect)\\\n",
        "                                             .withColumn('StudentId',\n",
        "                                                          split(col(\"studentId_clientType\"), \"@\").getItem(0))\\\n",
        "                                             .withColumn('ClientType', \n",
        "                                                          split(col(\"studentId_clientType\"), \"@\").getItem(1))\\\n",
        "                                              .drop('studentId_clientType')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5z31VzVKgF6"
      },
      "source": [
        "#@title Função similar a cleanString da primeira parte, com a diferença que aqui incluo ela no UDF. { display-mode: \"both\" }\n",
        "def cleanString(value):\n",
        "    value = re.sub(' +', ' ', str(value))\n",
        "    return normalize('NFKD', value).encode('ASCII', 'ignore').decode('ASCII').upper().strip()\n",
        "cleanStringUDF = udf(cleanString)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS-wyj7EjmxC"
      },
      "source": [
        "#@title Função similar a normalizeColumnsValues da primeira parte. { display-mode: \"both\" }\n",
        "def normalizeColumnsValues(dataframe):\n",
        "    for column in dataframe.columns:\n",
        "        dataframe = dataframe.withColumn(column, cleanStringUDF(column))\n",
        "    return dataframe "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEuwGEsjlKVH"
      },
      "source": [
        "dfPageViewEvents = normalizeColumnsValues(dfPageViewEvents)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FHXxU-gUMxH"
      },
      "source": [
        "#@title Dicionário para padronizar os nomes das colunas. { display-mode: \"both\" }\n",
        "DictColumnToRename  = {'Page Category':'PageCategory',\n",
        "                      'Page Category 1':'PageCategory_1',\n",
        "                      'Page Category 2':'PageCategory_2',\n",
        "                      'Page Category 3':'PageCategory_3',\n",
        "                      'at':'AccessDateTime',\n",
        "                      'browser':'Browser',\n",
        "                      'carrier':'InternetProvider',\n",
        "                      'custom_4':'UserAccessCategory',\n",
        "                      'first-accessed-page':'FirstAccessedPage',\n",
        "                      'marketing_campaign':'MarketingCampaign',\n",
        "                      'marketing_medium':'MarketingMedium',\n",
        "                      'marketing_source':'MarketingSource',\n",
        "                      'model':'Model',\n",
        "                      'platform':'OS',\n",
        "                      'uuid':'UuidPageViewEvents'}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTYt-56uYegb"
      },
      "source": [
        "for columnAsIs,columnToBe in DictColumnToRename.items():\r\n",
        "  dfPageViewEvents = dfPageViewEvents.withColumnRenamed(columnAsIs, columnToBe) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa-a8O3a2_9k"
      },
      "source": [
        "#@title Foquei a análise em entender os valores 'NONE' e 'UNDEFINED' que existem na colunas que eu selecionei. Após realizar algumas simulações de filtros e resultados, decidi apenas por remover os StudentId que possuíam 'NONE'. As PageCategory geraram bastante dúvida, mas decidi deixa-las por entender que alguns comportamentos podem ser identificados utilizando as 4 categorias. \n",
        "dfPageViewEvents = dfPageViewEvents.where(col('StudentId') != 'NONE')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkP7tmLMyrUl",
        "outputId": "f470791f-3a8d-4f00-d95d-5319354b9dc9"
      },
      "source": [
        "#@title Transformei essa operação em função para não impactar no tempo/custo da execução do ETL, e também para manter no notebook de onde tirei os percentuais de 'NONE' para passar para a área cliente. Achei que o conteúdo das colunas Marketing pode ser relevante, mas é bom destacar elas só possuem informação em 4% da base.\n",
        "# def percentageOfNoneInEachColumn():\n",
        "listColumns = dfPageViewEvents.columns\n",
        "sizeDataframe = dfPageViewEvents.count()\n",
        "for column in listColumns: \n",
        "  print(column, round((dfPageViewEvents.where(col(column) == 'NONE').count() / sizeDataframe),2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PageCategory 0.0\n",
            "PageCategory_1 0.13\n",
            "PageCategory_2 0.13\n",
            "PageCategory_3 0.14\n",
            "AccessDateTime 0.0\n",
            "Browser 0.0\n",
            "InternetProvider 0.0\n",
            "UserAccessCategory 0.07\n",
            "FirstAccessedPage 0.28\n",
            "MarketingCampaign 0.96\n",
            "MarketingMedium 0.96\n",
            "MarketingSource 0.96\n",
            "Model 0.0\n",
            "OS 0.0\n",
            "UuidPageViewEvents 0.0\n",
            "StudentId 0.0\n",
            "ClientType 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OtweXVTsAuG"
      },
      "source": [
        "#@title Salva o arquivo no seu drive em formato json.\n",
        "outputPath = '/content/drive/MyDrive/passeiDireto/page_view_events.json'\n",
        "dfPageViewEvents.write.format('json').mode('overwrite').json(outputPath)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}